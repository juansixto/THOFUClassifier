 package DemoClassify;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Properties;

import edu.stanford.nlp.classify.RVFDataset;
import edu.stanford.nlp.ling.CoreAnnotations.PrevChildAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.RVFDatum;
import edu.stanford.nlp.ling.CoreAnnotations.LemmaAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.PartOfSpeechAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TextAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;

import edu.stanford.nlp.stats.ClassicCounter;
import edu.stanford.nlp.util.CoreMap;
import Corpus.Document;
import Corpus.Corpus;
import Qwordnet.QWordNetDB;

public class CorpusTestGenerator2 {
	
	private final static String[] NEGATION_TOKENS = {"not", "nt", "neither", "nor"};
	static int TestSplit = 10; //%
	int Num_Test = 0;
	int Num_Train = 0;
	TaxonomyClass myTC = new TaxonomyClass();
	List<String> RoomSentences = new ArrayList();
	List<String> ServiceSentences = new ArrayList();
	List<String> StaffSentences = new ArrayList();
	List<String> FacilitiesSentences = new ArrayList();
	
	
	public String Generate(Corpus corpus) throws IOException
	{
		
		int CorpusMax= (corpus.size())*TestSplit/100;
		QWordNetDB qwordnet = QWordNetDB.createInstance();
		int Num_Test = 0;
		int Num_Train = 0;
		Properties props = new Properties();
		props.put("annotators", "tokenize, ssplit, pos, lemma");
		String  tFichero = "data/THOFUDemo.test";
		String  trFichero = "data/THOFUDemo.train";
		String  tRating = "data/THOFUDemoClass.test";
		File  TrainFile = new File (trFichero);
		File  TestFile = new File (tFichero);
		File  RatingFile = new File (tRating);
		BufferedWriter  trainf = new BufferedWriter (new FileWriter (TrainFile));
		BufferedWriter  testf = new BufferedWriter (new FileWriter (TestFile));
		BufferedWriter  ratingf = new BufferedWriter (new FileWriter (RatingFile));
		
		StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
		RVFDataset<String, String> dataset = new RVFDataset<String, String>();
		int nDoc = 1;
		for (Document doc : corpus) {
			
			final Annotation document = new Annotation(doc.getText());
			pipeline.annotate(document);

			final List<CoreMap> sentences = document.get(SentencesAnnotation.class);

			ClassicCounter<String> featureCounter = new ClassicCounter<String>();
			for (int h = 0; h < sentences.size(); h++) {
				final CoreMap sentence = sentences.get(h);
				final List<CoreLabel> tokens = sentence.get(TokensAnnotation.class);
				final Iterator<CoreLabel> it = tokens.iterator();
				
				while(it.hasNext()) {
					final String pos = it.next().get(PartOfSpeechAnnotation.class);
					if(pos.equals(".") || pos.equals(",") || pos.equals("``")) {
						it.remove();
					}
				}
				
				boolean negate = false;
				
				for (int i = 0; i < tokens.size(); i++) {		
										
					final CoreLabel token = tokens.get(i);
					String lemma = token.get(LemmaAnnotation.class).toLowerCase();
					String word = token.get(TextAnnotation.class).toLowerCase();
					String wordPos = token.get(PartOfSpeechAnnotation.class);
					boolean located = false;
				
					//String lemma = getLemma(lemmatizer, word, wordPos);
					
					if(wordPos.startsWith("NN") || wordPos.startsWith("JJ") || wordPos.startsWith("RB")) {
						featureCounter.incrementCount("lemma_" + lemma);
						featureCounter.incrementCount("lemma_" + lemma + "_POS_" + wordPos);
						
						if(negate) {
							featureCounter.incrementCount("not_lemma_" + lemma);
						}
					}
					
					if(wordPos.startsWith("JJ")) {
						String RelWord = "";
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma-1_" + ((i == 0)?"<s>":tokens.get(i-1).get(LemmaAnnotation.class).toLowerCase()));
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma+1_" + ((i == tokens.size() - 1)?"</s>":tokens.get(i+1).get(LemmaAnnotation.class).toLowerCase()));
						for(int j = 1; j < 3; j++) {
							if(i+j<tokens.size()){
								if(tokens.get(i+j).get(PartOfSpeechAnnotation.class).startsWith("NN")) {
									RelWord = tokens.get(i+j).get(TextAnnotation.class).toLowerCase();
									String prevLemma = tokens.get(i+j).get(LemmaAnnotation.class).toLowerCase();
									String prevLemmaPos = tokens.get(i+j).get(PartOfSpeechAnnotation.class);
									featureCounter.incrementCount("lemma_" + prevLemma + "_jj_" + lemma);
									//System.out.println(sentence.toString());
									//System.out.println("lemma_" + lemma + "_jj_" + prevLemma + "_polarity_"+qwordnet.getPolarity(lemma, wordPos));
									final String polarityFeature = "lemma_" + prevLemma + "_jj_" + lemma+ "_polarity_"+qwordnet.getPolarity(lemma, wordPos);
								final boolean negative = negate != (( qwordnet.getPolarity(lemma, wordPos)) < 0);
									if(negative && (myTC.SearchAllFeature(RelWord))) {
										featureCounter.decrementCount(polarityFeature);
									} else {
										featureCounter.incrementCount(polarityFeature);
									}
									located = true;
								}
							}
							if ((i-j)>0){
								if(tokens.get(i-j).get(PartOfSpeechAnnotation.class).startsWith("NN")) {
									RelWord = tokens.get(i-j).get(TextAnnotation.class).toLowerCase();
									String prevLemma = tokens.get(i-j).get(LemmaAnnotation.class).toLowerCase();
									String prevLemmaPos = tokens.get(i-j).get(PartOfSpeechAnnotation.class);
									featureCounter.incrementCount("lemma_" + prevLemma + "_jj_" + lemma);
									final String polarityFeature = "lemma_" + prevLemma + "_jj_" + lemma +"_polarity_"+qwordnet.getPolarity(lemma, wordPos);
								final boolean negative = negate != (( qwordnet.getPolarity(lemma, wordPos)) < 0);
									if(negative && (myTC.SearchAllFeature(RelWord))) {
										featureCounter.decrementCount(polarityFeature);
									} else {
										featureCounter.incrementCount(polarityFeature);
									}
									located = true;
								}
							}
							if(located)
							{
								located = false;
								break;
							}
						}
					} else if(wordPos.startsWith("JJ")) {
						
					}
					
					if(!negate) {
						//String word = tokens.get(i).get(TextAnnotation.class);
						for(String negationToken: NEGATION_TOKENS) {
							if(negationToken.equals(word)) {
								negate = true;
								break;
							}
						}
					}
				}
			}
			dataset.add(new RVFDatum<String, String>(featureCounter, doc.getClassification()));
			String temp = featureCounter.toString();
			temp = temp.replace(" ", "");
			temp = temp.replace("{", "");
			temp = temp.replace("}", "");
			
			double rnd = Math.random()*100;
			
			;
			
			/*if ((rnd > TestSplit) &&( Num_Test <=CorpusMax)){
			trainf.write(doc.getClassification() +"	" +temp+"\n");
			Num_Train++;}
			else{
				testf.write(doc.getClassification() +"	" +temp+"\n");
				ratingf.write(doc.getRating() +"	" +temp+"\n");
				//System.out.println(doc.getClassification() + " == " + doc.getRating() );
			Num_Test++;}*/
			trainf.write(doc.getClassification() +"	" +temp+"\n");
			testf.write(doc.getClassification() +"	" +temp+"\n");
			ratingf.write(doc.getRating() +"	" +temp+"\n");
			
		}
		String resp = "Total items: " + (Num_Test+Num_Train) + "Total test items: " + Num_Test + "Total train items: " + Num_Train ;
		System.out.println(CorpusMax);
		System.out.println("Data files created");
		System.out.println("Total items: " + (Num_Test+Num_Train));
		System.out.println("Total test items: " + Num_Test);
		System.out.println("Total train items: " + Num_Train);
		return resp;
		}
	
	public void PrintResults(){
		
		System.out.println("Data files created");
		System.out.println("Total items: " + (Num_Test+Num_Train));
		System.out.println("Total test items: " + Num_Test);
		System.out.println("Total train items: " + Num_Train);
		}
	
	
	
	public String GenerateSentence(String INsentence) throws IOException
	{
		
		
		RoomSentences = new ArrayList();
		ServiceSentences = new ArrayList();
		StaffSentences = new ArrayList();
		FacilitiesSentences = new ArrayList();
		
		QWordNetDB qwordnet = QWordNetDB.createInstance();
		
		Properties props = new Properties();
		props.put("annotators", "tokenize, ssplit, pos, lemma");
	
		
		StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
		RVFDataset<String, String> dataset = new RVFDataset<String, String>();
		
			
			final Annotation document = new Annotation(INsentence);
			pipeline.annotate(document);

			final List<CoreMap> sentences = document.get(SentencesAnnotation.class);

			ClassicCounter<String> featureCounter = new ClassicCounter<String>();
			for (int h = 0; h < sentences.size(); h++) {
				final CoreMap sentence = sentences.get(h);
				final List<CoreLabel> tokens = sentence.get(TokensAnnotation.class);
			
				final Iterator<CoreLabel> it = tokens.iterator();
				
				while(it.hasNext()) {
					final String pos = it.next().get(PartOfSpeechAnnotation.class);
					if(pos.equals(".") || pos.equals(",") || pos.equals("``")) {
						it.remove();
					}
				}
				
				boolean negate = false;
				boolean roomFeat = false;
				boolean serviceFeat = false;
				boolean staffFeat = false;
				boolean facilityFeat = false;
				
				for (int i = 0; i < tokens.size(); i++) {
							
					final CoreLabel token = tokens.get(i);
					String lemma = token.get(LemmaAnnotation.class).toLowerCase();
					
					String word = token.get(TextAnnotation.class).toLowerCase();
					String wordPos = token.get(PartOfSpeechAnnotation.class);
					//System.out.println(word + " " + wordPos + " " +lemma);
					
					if(myTC.SearchFeature(word,0)){ System.out.println("Encontado Feat: " + word);roomFeat = true;}
					if(myTC.SearchFeature(word,1)){ System.out.println("Encontado Feat: " + word);serviceFeat = true;}
					if(myTC.SearchFeature(word,2)){ System.out.println("Encontado Feat: " + word);staffFeat = true;}
					if(myTC.SearchFeature(word,3)){ System.out.println("Encontado Feat: " + word);facilityFeat = true;}
					//String lemma = getLemma(lemmatizer, word, wordPos);
					
					if(wordPos.startsWith("NN") || wordPos.startsWith("JJ") || wordPos.startsWith("RB")) {
						featureCounter.incrementCount("lemma_" + lemma);
						featureCounter.incrementCount("lemma_" + lemma + "_POS_" + wordPos);
						
						if(negate) {
							featureCounter.incrementCount("not_lemma_" + lemma);
						}
					}
					/*
					if(wordPos.startsWith("JJ")) {
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma-1_" + ((i == 0)?"<s>":tokens.get(i-1).get(LemmaAnnotation.class).toLowerCase()));
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma+1_" + ((i == tokens.size() - 1)?"</s>":tokens.get(i+1).get(LemmaAnnotation.class).toLowerCase()));
						for(int j = i - 1; j >= 0; j--) {
							if(tokens.get(j).get(PartOfSpeechAnnotation.class).startsWith("JJ")) {
								String prevLemma = tokens.get(j).get(LemmaAnnotation.class).toLowerCase();
								String prevLemmaPos = tokens.get(j).get(PartOfSpeechAnnotation.class);
								featureCounter.incrementCount("lemma_" + lemma + "_jj_" + prevLemma);
								System.out.println("QWordNet:    " +lemma +"	"+ wordPos + "	"+ qwordnet.getPolarity(lemma, wordPos));
								final String polarityFeature = "lemma_" + lemma + "_polarity";
							final boolean negative = negate != ((qwordnet.getPolarity(prevLemma, prevLemmaPos) * qwordnet.getPolarity(lemma, wordPos)) < 0);
								if(negative) {
									featureCounter.decrementCount(polarityFeature);
								} else {
									featureCounter.incrementCount(polarityFeature);
								}
								//System.out.println(word +" - " + featureCounter);
								break;
							}
						}
					} else if(wordPos.startsWith("JJ")) {
						
					}*/
					
					/////////////////////////////////////////////////
					
					if(wordPos.startsWith("NN")) {
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma-1_" + ((i == 0)?"<s>":tokens.get(i-1).get(LemmaAnnotation.class).toLowerCase()));
						//featureCounter.incrementCount("lemma_" + lemma + "_lemma+1_" + ((i == tokens.size() - 1)?"</s>":tokens.get(i+1).get(LemmaAnnotation.class).toLowerCase()));
						for(int j = i - 1; j >= 0; j--) {
							if(tokens.get(j).get(PartOfSpeechAnnotation.class).startsWith("JJ")) {
								String prevLemma = tokens.get(j).get(LemmaAnnotation.class).toLowerCase();
								String prevLemmaPos = tokens.get(j).get(PartOfSpeechAnnotation.class);
								featureCounter.incrementCount("lemma_" + lemma + "_jj_" + prevLemma);
								System.out.println("QWordNet:    " +lemma +"	"+ wordPos + "	"+ qwordnet.getPolarity(lemma, wordPos));
								final String polarityFeature = "lemma_" + lemma + "_polarity" + qwordnet.getPolarity(lemma, wordPos);
							final boolean negative = negate != ((qwordnet.getPolarity(prevLemma, prevLemmaPos) * qwordnet.getPolarity(lemma, wordPos)) < 0);
								if(negative) {
									featureCounter.decrementCount(polarityFeature);
								} else {
									featureCounter.incrementCount(polarityFeature);
								}
								//System.out.println(word +" - " + featureCounter);
								break;
							}
						}
					} else if(wordPos.startsWith("JJ")) {
						
					}
					/////////////////////////////////////////////////
					
					if(!negate) {
						//String word = tokens.get(i).get(TextAnnotation.class);
						for(String negationToken: NEGATION_TOKENS) {
							if(negationToken.equals(word)) {
								negate = true;
								break;
							}
						}
					}
					
				}
				if(roomFeat){
					RoomSentences.add(sentence.toString());
					}
				if(serviceFeat){
					ServiceSentences.add(sentence.toString());
					}
				if(staffFeat){
					StaffSentences.add(sentence.toString());
					}
				if(facilityFeat){
					FacilitiesSentences.add(sentence.toString());
					}
			}

			String temp = featureCounter.toString();
		
			
			String resp = "AA" + "	" +temp;
			System.out.println("Respuesta:  "+ resp);
			
			
			
				
		return resp;
		}
	}
	

